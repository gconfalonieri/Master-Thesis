#
# Configuration File
#

[general]
media_list = ['NewMedia1', 'NewMedia2', 'NewMedia3', 'NewMedia4', 'NewMedia5', 'NewMedia6', 'NewMedia7', 'NewMedia8',
    'NewMedia9', 'NewMedia10', 'NewMedia11', 'NewMedia12', 'NewMedia13', 'NewMedia14', 'NewMedia15', 'NewMedia16',
    'NewMedia17', 'NewMedia18', 'NewMedia19', 'NewMedia20', 'NewMedia21', 'NewMedia22', 'NewMedia23', 'NewMedia24']
n_testers = 52
n_valid_testers = 46
n_epochs = 100
n_questions = 24
excluded_media = [12, 16, 17]
excluded_media_list_mean = [[16], [16, 17], [12, 16, 17], [12, 15, 16, 17], [2, 12, 15, 16, 17], [2, 3, 12, 15, 16, 17],
    [2, 3, 12, 15, 16, 17, 20], [2, 3, 12, 15, 16, 17, 20, 21], [2, 3, 12, 13, 15, 16, 17, 20, 21],
    [1, 2, 3, 12, 13, 15, 16, 17, 20, 21], [1, 2, 3, 10, 12, 13, 15, 16, 17, 20, 21],
    [1, 2, 3, 10, 12, 13, 15, 16, 17, 20, 21, 18]]
excluded_media_list_std = [[11], [9, 11], [9, 11, 19], [9, 11, 19, 23], [8, 9, 11, 19, 23], [8, 9, 10, 11, 19, 23],
    [8, 9, 10, 11, 13, 19, 23], [8, 9, 10, 11, 13, 19, 22, 23], [5, 8, 9, 10, 11, 13, 19, 22, 23],
    [5, 7, 8, 9, 10, 11, 13, 19, 22, 23], [5, 7, 8, 9, 10, 11, 13, 18, 19, 22, 23],
    [5, 7, 8, 9, 10, 11, 13, 18, 19, 21, 22, 23] ]
reduced_test_users = [25, 26, 30]
not_valid_users = [5, 23, 25, 26, 30, 50]
excluded_users = [5, 23, 25, 26, 30, 50, 1, 10, 20, 35, 40]
validation_users = [1, 10, 20, 35, 40]
excluded_users_list = [
    [5, 23, 25, 26, 30, 50, 1, 10, 20, 35, 40],
    [5, 23, 25, 26, 30, 50, 3, 7, 15, 33, 37],
    [5, 23, 25, 26, 30, 50, 2, 11, 24, 45, 49],
    [5, 23, 25, 26, 30, 50, 4, 14, 34, 44, 46],
    [5, 23, 25, 26, 30, 50, 8, 17, 27, 39, 47]
]
validation_users_list = [
    [1, 10, 20, 35, 40],
    [3, 7, 15, 33, 37],
    [2, 11, 24, 45, 49],
    [4, 14, 34, 44, 46],
    [8, 17, 27, 39, 47]
]

binary_value = [0, 1]
binary_value_single = [1]
data_source = 'EYE'
is_filter = 0
is_ordered = 0

[path]
brainwaves_folder = './datasets/eeg'
solutions_complete_dataset = './datasets/questions/solutions_complete.csv'
answers_complete_dataset = './datasets/questions/answers_complete.csv'
labelled_dataset = './datasets/results/labels/labelled_dataset_v2.csv'
sync_prefix_eye = 'datasets/sync_datasets/normalized/norm_1_1/'
sync_validation_prefix_eye = 'datasets/sync_datasets/normalized/norm_1_1/'
sync_prefix_eeg = 'datasets/sync_datasets/normalized/norm_1_1_eeg/'
sync_validation_prefix_eeg = 'datasets/sync_datasets/normalized/norm_1_1_eeg/'

plots_prefix = 'plots/plots_eye_validation/'

filename_results = 'results_eye_validation.csv'
filename_performances_cross_corr = 'performances_cross_12345_eye_validation.csv'
filename_performances_aggregate = 'performances_aggr_12345_eye_validation.csv'
filename_performances_validation = 'performances_val_12345_eeg_validation.csv'
filename_learning_rate = 'learning_rate.csv'

filename_validation_aggr = 'validation_aggr_12345_eye.csv'
filename_validation_cross_corr = 'validation_cross_12345_eye.csv'

input_arrays = ['datasets/arrays/shifted/users_input_1_1.npy']
labels_arrays = ['datasets/arrays/labels/users_labels_v2.npy']

[random_seed]
seed_list = [12345, 2002, 210632, 220301, 869430]
unique_seed = 12345
pythonhashseed = 12345
python_seed = 12345
numpy_seed = 12345 # same as scipy seed
tf_seed = 12345
keras_seed = 12345

[algorithm]
model = ['P-L']
eeg_features = ['delta', 'alpha1', 'alpha2', 'theta', 'beta1', 'beta2', 'gamma1', 'gamma2']
# 'alpha1', 'alpha2', 'beta1', 'beta2', 'delta', 'gamma1', 'gamma2'
gaze_features = ['FPOGX', 'FPOGY', 'RPD', 'LPD'] # 'FPOGV' (test come maschera)
fpogv_mask = ['FPOGV']
test_size = 0.20 # 0.13
min_len_thr = 662
n_kfold_splits = 5
n_cnn_filters = [32, 64] # 512, 1024
cnn_kernel_size = [3, 4] # 4, 8, 10
n_cnn_filters_2 = [32, 64] # 512, 1024
cnn_kernel_size_2 = [3, 4] # 4, 8, 10
cnn_pool_size = [3, 4] # 2, 4, 8
n_lstm_units = [32, 64] # 32, 64, 128
dropout_value = [0.1, 0.2, 0.5] # 0.1, 0.2, 0.5
dense_input_dim = [2646] # 2646, 265 half
input_activation_types = ['relu'] # linear, softmax
output_activation_types = ['relu']
loss_types = ['mean_squared_error']
optimizer_types = ['adam'] # 'SGD', 'Ftrl', 'Adadmax'
# activation_types = ['relu', 'tanh', 'leaky_relu', 'para_relu', 'elu', 'linear']
# loss_types = ['mean_squared_error', 'mean_absolute_error', 'cosine_similarity', 'binary_crossentropy', 'categorical_crossentropy', 'poisson', 'sparse_categorical_crossentropy', 'hinge']
# optimizer_types = ['adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']

[preprocessing]
min_normalization = -1
max_normalization  = 1
interpolation_kind = 'linear'
sync_normalization = true
resample_library = 'scipy'

[computed]
shifted_max_len = 2646

[parallel_model]
dense_input_1 = 2646
activation_input_1 = 'relu'
lstm_1 = 64
dense_1_1 = 128
dense_input_2 = 265
lstm_2 = 64
activation_input_2 = 'relu'
dense_2_1 = 64